{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edd7f18f-0e9d-4cb7-9334-7ec009b6efdf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plotting_util \u001b[38;5;28;01mas\u001b[39;00m putil\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfnmatch\u001b[39;00m\n",
      "File \u001b[0;32m/lila/data/morrisq/divyak/projects/met_history_prediction/src/util/plotting_util.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmcolors\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[0;32m/lila/home/koyyald/mambaforge/envs/met/lib/python3.8/site-packages/networkx/__init__.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_imports\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _lazy_import\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classes\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m filters\n",
      "File \u001b[0;32m/lila/home/koyyald/mambaforge/envs/met/lib/python3.8/site-packages/networkx/utils/__init__.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrandom_sequence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munion_find\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrcm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mheaps\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:971\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:914\u001b[0m, in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1342\u001b[0m, in \u001b[0;36mfind_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1314\u001b[0m, in \u001b[0;36m_get_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1469\u001b[0m, in \u001b[0;36mfind_spec\u001b[0;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:101\u001b[0m, in \u001b[0;36m_path_isfile\u001b[0;34m(path)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:93\u001b[0m, in \u001b[0;36m_path_is_mode_type\u001b[0;34m(path, mode)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:87\u001b[0m, in \u001b[0;36m_path_stat\u001b[0;34m(path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from src.util import plotting_util as putil\n",
    "import pandas as pd\n",
    "import fnmatch\n",
    "from src.util import eval_util as eutil\n",
    "import seaborn as sns\n",
    "\n",
    "REPO_DIR = os.path.join(os.getcwd(), \"../\")\n",
    "os.chdir(REPO_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc5a108",
   "metadata": {},
   "outputs": [],
   "source": [
    "SITES = [\"m5\", \"m8\"]\n",
    "MIG_TYPES = [\"mS\", \"M\", \"S\", \"R\"]\n",
    "CUTOFF = 1.0\n",
    "k = 5\n",
    "DATE = \"11162023\"\n",
    "PARAMS = \"calibrate_wip\"\n",
    "MODE = \"calibrate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565ae6e1-dbe3-42ea-a699-6ed17d432489",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get number of clusters (tree vertices to label) per site/mig_type/seed combo\n",
    "def get_num_mut_trees(mut_tree_fn):\n",
    "    with open(mut_tree_fn, 'r') as f:\n",
    "        # look for line w/ \"3 #trees\" as an example\n",
    "        for line in f:\n",
    "            if  \"#trees\" in line:\n",
    "                return int(line.strip().split()[0])\n",
    "sims_dir = os.path.join(REPO_DIR, \"data/machina_sims\")\n",
    "data = []\n",
    "tot = 0\n",
    "for site in SITES:\n",
    "    for mig_type in MIG_TYPES:\n",
    "        site_mig_type_dir = os.path.join(sims_dir, site, mig_type)\n",
    "        seeds = fnmatch.filter(os.listdir(site_mig_type_dir), 'clustering_observed_seed*.txt')\n",
    "        seeds = [s.replace(\".txt\", \"\").replace(\"clustering_observed_seed\", \"\") for s in seeds]\n",
    "        for seed in seeds:\n",
    "            fn = os.path.join(site_mig_type_dir, f\"clustering_observed_seed{seed}.txt\")\n",
    "            num_lines = sum(1 for _ in open(fn))\n",
    "            fn = os.path.join(site_mig_type_dir, f\"T_seed{seed}.labeling\")\n",
    "            sites = set()\n",
    "            with open(fn) as f:\n",
    "                for line in f:\n",
    "                    sites.add(line.strip().split()[1])\n",
    "            n = get_num_mut_trees(os.path.join(sims_dir, f\"{site}_mut_trees\", f\"mut_trees_{mig_type}_seed{seed}.txt\"))\n",
    "            #print(n)\n",
    "            tot+=n\n",
    "            for i in range(n):\n",
    "                data.append([seed, site, mig_type, num_lines, len(sites), i])\n",
    "print(\"tot\",tot)\n",
    "cols = [\"seed\", \"site\", \"mig_type\", \"clusters\", \"sites\", \"tree_num\"]\n",
    "cluster_num_df = pd.DataFrame(data, columns=cols)\n",
    "cluster_num_df[\"seed\"] = cluster_num_df[\"seed\"].astype(int)\n",
    "print(cluster_num_df['clusters'].max())\n",
    "\n",
    "cluster_num_df['cluster_bins'] = pd.qcut(cluster_num_df['clusters'], 3, labels=False, duplicates='drop')\n",
    "denom=10000\n",
    "def calc_prob_size(num_sites, num_nodes):\n",
    "    return (num_sites**(num_nodes-1))\n",
    "cluster_num_df['prob_size'] = cluster_num_df.apply(lambda row: calc_prob_size(row[\"sites\"], row['clusters'])/denom, axis=1)\n",
    "cluster_num_df['prob_size_bins'] = pd.qcut(cluster_num_df['prob_size'], 3, labels=False, duplicates='drop')\n",
    "\n",
    "sns.histplot(cluster_num_df['clusters'], kde=True, color='skyblue')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e85659c-f352-438b-8e0c-47f5b8faf17f",
   "metadata": {},
   "source": [
    "### Evaluate Metient's best trees based on batch size, tree size and number of anatomical sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a50953-d7a2-47a5-abd6-a2ab8e75e7cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "batch_sizes = ['64', '256', '1024']\n",
    "num_runs = 5\n",
    "\n",
    "bs_to_num_nodes_to_ground_truth_slns = {bs:{} for bs in batch_sizes}\n",
    "bs_to_num_sites_to_ground_truth_slns = {bs:{} for bs in batch_sizes}\n",
    "bs_to_prob_size_bin_to_ground_truth_slns = {bs:{} for bs in batch_sizes}\n",
    "\n",
    "for bs in batch_sizes:\n",
    "    for run in range(1,num_runs+1):\n",
    "        prediction_dir = os.path.join(REPO_DIR, 'test', 'machina_simulated_data', f'batch_experiments_{DATE}', f'predictions_bs{bs}_{PARAMS}_r{run}_{DATE}')\n",
    "\n",
    "        print(prediction_dir)\n",
    "        grad_m5_f1_scores = []\n",
    "        grad_m8_f1_scores = []\n",
    "        ct = 0\n",
    "        tot = 0\n",
    "        for site in SITES:\n",
    "            for mig_type in tqdm(MIG_TYPES):\n",
    "                true_site_mig_type_data_dir = os.path.join(sims_dir, site, mig_type)\n",
    "                predicted_site_mig_type_data_dir = os.path.join(prediction_dir, site, mig_type)\n",
    "                filenames = fnmatch.filter(os.listdir(predicted_site_mig_type_data_dir), 'T_tree*.predicted.tree')\n",
    "                seeds = set([int(s[s.find(\"seed\")+4:s.find(\".predicted\")]) for s in filenames])\n",
    "                for seed in seeds:\n",
    "                    seed_filenames = [f for f in filenames if seed == f[f.find(\"seed\")+4:f.find(\".predicted\")]]\n",
    "                    tree_info = eutil.get_metient_min_loss_trees(predicted_site_mig_type_data_dir, seed, k, loss_thres=0.0)\n",
    "                    ground_truth_clones_found = False\n",
    "                    ground_truth_mig_graph_found = False\n",
    "                    Fs, F_G2s = [], []\n",
    "\n",
    "                    for i, (loss, met_results_dict, met_tree_num) in enumerate(tree_info):\n",
    "                        recall, precision, F, has_resolved_polytomy = eutil.evaluate_seeding_clones(os.path.join(true_site_mig_type_data_dir, f\"T_seed{seed}.tree\"),\n",
    "                                                                      os.path.join(true_site_mig_type_data_dir, f\"T_seed{seed}.vertex.labeling\"),\n",
    "                                                                      met_results_dict, met_tree_num)\n",
    "\n",
    "                        if F >= CUTOFF:\n",
    "                            ground_truth_clones_found = True\n",
    "\n",
    "                        recall_G2, precision_G2, F_G2 = eutil.evaluate_migration_multigraph(os.path.join(true_site_mig_type_data_dir, f\"G_seed{seed}.tree\"),\n",
    "                                                                                            met_results_dict, met_tree_num)\n",
    "                        if F_G2 >= CUTOFF:\n",
    "                            ground_truth_mig_graph_found = True   \n",
    "                        Fs.append(F)\n",
    "                        F_G2s.append(F_G2)\n",
    "                    subset_df = cluster_num_df[(cluster_num_df['seed']==int(seed))&(cluster_num_df['site']==site)&(cluster_num_df['mig_type']==mig_type)]\n",
    "                    num_nodes = subset_df.iloc[0]['clusters']\n",
    "                    rng = subset_df['cluster_bins'].unique().item()\n",
    "                    if rng not in bs_to_num_nodes_to_ground_truth_slns[bs]:\n",
    "                        bs_to_num_nodes_to_ground_truth_slns[bs][rng] = []\n",
    "                    if sum(Fs)/len(Fs) < min(Fs):\n",
    "                        ct += 1\n",
    "                    tot+= 1\n",
    "                    info = (ground_truth_clones_found, ground_truth_mig_graph_found, sum(Fs)/len(Fs), sum(F_G2s)/len(F_G2s))\n",
    "                    bs_to_num_nodes_to_ground_truth_slns[bs][rng].append(info)\n",
    "\n",
    "                    num_sites = subset_df.iloc[0]['sites']\n",
    "                    if num_sites not in bs_to_num_sites_to_ground_truth_slns[bs]:\n",
    "                        bs_to_num_sites_to_ground_truth_slns[bs][num_sites] = []\n",
    "                    bs_to_num_sites_to_ground_truth_slns[bs][num_sites].append(info)\n",
    "                    \n",
    "                    prob_size_bin = subset_df['prob_size_bins'].unique().item()\n",
    "                    if prob_size_bin not in bs_to_prob_size_bin_to_ground_truth_slns[bs]:\n",
    "                        bs_to_prob_size_bin_to_ground_truth_slns[bs][prob_size_bin] = []\n",
    "                    bs_to_prob_size_bin_to_ground_truth_slns[bs][prob_size_bin].append(info)\n",
    "\n",
    "bs_to_prob_size_bin_to_ground_truth_slns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079539a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_num_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92212438-2f88-483f-9500-bac446f64a9c",
   "metadata": {},
   "source": [
    "### Load machina results for comparison #TODO: use multiple runs for MACHINA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f16212-1286-4bef-a224-18eafb4db405",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mach_node_size_to_ground_truth_slns = {}\n",
    "mach_num_sites_to_ground_truth_slns = {}\n",
    "mach_prob_size_bin_to_ground_truth_slns = {}\n",
    "\n",
    "machina_m5_df, machina_m8_df = eutil.load_machina_results(os.path.join(REPO_DIR, 'test/machina_simulated_data'))\n",
    "col_mapping = {\"FscoreT\": \"migrating clones F1 score\", \"FscoreMultiG\": \"migration graph F1 score\", \"pattern\": \"seeding pattern\", \"seed\":\"seed\"}\n",
    "machina_m5_df = machina_m5_df.rename(columns=col_mapping)\n",
    "machina_m8_df = machina_m8_df.rename(columns=col_mapping)\n",
    "for site, df in zip(['m5', 'm8'],[machina_m5_df, machina_m8_df]):\n",
    "    for i, row in df.iterrows():\n",
    "        pattern = row['seeding pattern'].replace(\"p\", \"\")\n",
    "        subset_df = cluster_num_df[(cluster_num_df['seed']==int(row['seed']))&(cluster_num_df['site']==site)&(cluster_num_df['mig_type']==pattern)]\n",
    "        num_nodes = subset_df.iloc[0]['clusters']\n",
    "        rng = subset_df['cluster_bins'].unique().item()\n",
    "        num_sites = subset_df.iloc[0]['sites']\n",
    "        if rng not in mach_node_size_to_ground_truth_slns:\n",
    "            mach_node_size_to_ground_truth_slns[rng] = []\n",
    "        if num_sites not in mach_num_sites_to_ground_truth_slns:\n",
    "            mach_num_sites_to_ground_truth_slns[num_sites] = []\n",
    "            \n",
    "        prob_size_bin = subset_df['prob_size_bins'].unique().item()\n",
    "        if prob_size_bin not in mach_prob_size_bin_to_ground_truth_slns:\n",
    "            mach_prob_size_bin_to_ground_truth_slns[prob_size_bin] = []\n",
    "        \n",
    "            \n",
    "        ground_truth_clones_found = False\n",
    "        ground_truth_mig_graph_found = False\n",
    "        if float(row['migrating clones F1 score']) >= CUTOFF:\n",
    "            ground_truth_clones_found = True\n",
    "        if float(row['migration graph F1 score']) >= CUTOFF:\n",
    "            ground_truth_mig_graph_found = True\n",
    "        info = (ground_truth_clones_found, ground_truth_mig_graph_found, row['migrating clones F1 score'], row['migration graph F1 score'])\n",
    "        mach_node_size_to_ground_truth_slns[rng].append(info)\n",
    "        mach_num_sites_to_ground_truth_slns[num_sites].append(info)\n",
    "        mach_prob_size_bin_to_ground_truth_slns[prob_size_bin].append(info)\n",
    "mach_node_size_to_ground_truth_slns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdef4341-f3fe-4a8f-8505-aa28c2ecf54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_merged_results_df(met_dict, mach_dict, x, methods):\n",
    "    data = []\n",
    "    for bs in met_dict:\n",
    "        for key in met_dict[bs]:\n",
    "            gt_list = met_dict[bs][key]\n",
    "            percent_true_clones = sum(1 for item in gt_list if item[0]) / len(gt_list) * 100\n",
    "            percent_true_mig_graph = sum(1 for item in gt_list if item[1]) / len(gt_list) * 100\n",
    "            avg_clones_f1 = sum(item[2] for item in gt_list) / len(gt_list) * 100\n",
    "            avg_mig_graph_f1 = sum(item[3] for item in gt_list) / len(gt_list) * 100\n",
    "            data.append([f\"Metient-{bs}\", key, avg_clones_f1, avg_mig_graph_f1, percent_true_clones, percent_true_mig_graph])\n",
    "    \n",
    "    for key in mach_dict:\n",
    "        gt_list = mach_dict[key]\n",
    "        percent_true_clones = sum(1 for item in gt_list if item[0]) / len(gt_list) * 100\n",
    "        percent_true_mig_graph = sum(1 for item in gt_list if item[1]) / len(gt_list) * 100\n",
    "        avg_clones_f1 = sum(item[2] for item in gt_list) / len(gt_list) * 100\n",
    "        avg_mig_graph_f1 = sum(item[3] for item in gt_list) / len(gt_list) * 100\n",
    "        data.append([\"MACHINA\", key, avg_clones_f1, avg_mig_graph_f1, percent_true_clones, percent_true_mig_graph])\n",
    "    results = pd.DataFrame(data, columns=[\"Method\", x, \"Migrating clones F1-score\", \"Migration graph F1-score\", \"% time that migrating clone ground truth found\", \"% time that migration graph ground truth found\"])\n",
    "    return results\n",
    "\n",
    "methods = [\"Metient-64\", \"Metient-256\", \"Metient-1024\",]\n",
    "\n",
    "results1 = get_merged_results_df(bs_to_num_nodes_to_ground_truth_slns, mach_node_size_to_ground_truth_slns, \"Number of Tree Nodes\", methods)\n",
    "results2 = get_merged_results_df(bs_to_num_sites_to_ground_truth_slns, mach_num_sites_to_ground_truth_slns, \"Number of Anatomical Sites\", methods)\n",
    "results3 = get_merged_results_df(bs_to_prob_size_bin_to_ground_truth_slns, mach_prob_size_bin_to_ground_truth_slns, \"Size of Search Space Binned\", methods)\n",
    "# results4 = get_merged_results_df(bs_to_prob_size_to_ground_truth_slns, mach_prob_size_to_ground_truth_slns, \"Size of Search Space\", methods)\n",
    "\n",
    "results1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc98c20b-3fb1-41c1-9688-b4e9cf88041e",
   "metadata": {},
   "source": [
    "### Make plots for performance as a function of tree size, # anatomical sites, and size of search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb555c9-c25b-4ddc-99b4-7f701c8b9f05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "colors = sns.color_palette(\"crest\")\n",
    "colors = colors[:len(methods)]\n",
    "colors.append((0.99609375, 0.56640625, 0.37109375))\n",
    "print(colors)\n",
    "sns.set_palette(sns.color_palette(colors))\n",
    "\n",
    "ys = [\"Migrating clones F1-score\", \"Migration graph F1-score\", \"% time that migrating clone ground truth found\", \"% time that migration graph ground truth found\"]\n",
    "y_labels = [\"Migrating clones F1-score\", \"Migration graph F1-score\", \"Ground truth migrating\\n clones found (%)\", \"Ground truth migration\\n graph found (%)\"]\n",
    "out_names = [\"Migrating clones F1-score\", \"Migration graph F1-score\", \"Ground truth migrating clones found\", \"Ground truth migration graph found\"]\n",
    "\n",
    "def get_tree_node_bins():\n",
    "    bin_numbers = sorted(list(cluster_num_df['cluster_bins'].unique()))\n",
    "    bin_ranges = []\n",
    "    for bin_num in bin_numbers:\n",
    "        bin_min = cluster_num_df[cluster_num_df['cluster_bins']==bin_num]['clusters'].min()\n",
    "        bin_max = cluster_num_df[cluster_num_df['cluster_bins']==bin_num]['clusters'].max()\n",
    "        size = len(cluster_num_df[cluster_num_df['cluster_bins']==bin_num])\n",
    "        bin_ranges.append(f\"{bin_min}-{bin_max}\")\n",
    "        print(bin_num, bin_min, bin_max, size)\n",
    "    return bin_numbers, bin_ranges\n",
    "\n",
    "def get_prob_size_bins():\n",
    "    bin_numbers = sorted(list(cluster_num_df['prob_size_bins'].unique()))\n",
    "    bin_ranges = []\n",
    "    for bin_num in bin_numbers:\n",
    "        bin_min = cluster_num_df[cluster_num_df['prob_size_bins']==bin_num]['prob_size'].min()*denom\n",
    "        bin_minf = \"{:.1e}\".format(bin_min)\n",
    "        bin_max = cluster_num_df[cluster_num_df['prob_size_bins']==bin_num]['prob_size'].max()*denom\n",
    "        bin_maxf = \"{:.1e}\".format(bin_max)\n",
    "        size = len(cluster_num_df[cluster_num_df['prob_size_bins']==bin_num])\n",
    "        bin_ranges.append(f\"{bin_minf}-{bin_maxf}\")\n",
    "        print(bin_num, bin_minf, bin_maxf, size)\n",
    "    return bin_numbers, bin_ranges\n",
    "\n",
    "for x, df in zip([\"Number of Tree Nodes\", \"Number of Anatomical Sites\", \"Size of Search Space Binned\"], [results1, results2, results3]):\n",
    "    for i,y in enumerate(ys):\n",
    "        with sns.plotting_context(\"notebook\", font_scale=1.6):\n",
    "            g = sns.lineplot(\n",
    "                data=df, x=x, y=y,\n",
    "                hue=\"Method\", legend=False,  \n",
    "            )\n",
    "            if x == \"Number of Tree Nodes\":\n",
    "                bin_numbers, bin_ranges = get_tree_node_bins()\n",
    "                plt.xticks(ticks=bin_numbers,labels=bin_ranges)\n",
    "            if x == \"Size of Search Space Binned\":\n",
    "                bin_numbers, bin_ranges = get_prob_size_bins()\n",
    "                plt.xticks(ticks=bin_numbers,labels=bin_ranges)\n",
    "                plt.xticks(rotation=45)\n",
    "            if x == \"Size of Search Space\":\n",
    "                plt.xscale('log')\n",
    "            \n",
    "            if y == \"% time that migration graph ground truth found\":\n",
    "                plt.ylim(0, 50)\n",
    "            elif y == \"Migrating clones F1-score\":\n",
    "                plt.ylim(80, 100)\n",
    "            else:\n",
    "                plt.ylim(0, 100)\n",
    "                \n",
    "            legend = g.legend(prop={'size': 8})  # Set the desired font size here\n",
    "            g.spines['top'].set_visible(False)\n",
    "            g.spines['right'].set_visible(False)\n",
    "            \n",
    "            plt.ylabel(y_labels[i])\n",
    "            out_name = (\"_\").join(out_names[i].split(\" \") + x.split(\" \"))\n",
    "\n",
    "            plt.savefig(os.path.join(REPO_DIR, \"test/output_plots\", f\"{out_name}_10runs_lossthres{LOSS_THRES}_{PARAMS}_{DATE}.png\"), dpi=600, bbox_inches=\"tight\", pad_inches=0.3) \n",
    "\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b705ab7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7f75d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feef98f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mambaforge-met]",
   "language": "python",
   "name": "conda-env-mambaforge-met-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
