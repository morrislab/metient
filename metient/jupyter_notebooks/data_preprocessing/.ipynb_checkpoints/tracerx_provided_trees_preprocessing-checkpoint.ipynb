{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57150df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyreadr\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "REPO_DIR = os.path.join(os.getcwd(), \"../../\")\n",
    "\n",
    "TRACERX_DATA_DIR = \"/data/morrisq/divyak/data/tracerx_nsclc_2023/tracerx_full_tree_output_extracted\"\n",
    "OUTPUT_DIR = os.path.join(REPO_DIR, \"data/tracerx_nsclc/tracerx_provided_patient_data\")\n",
    "\n",
    "# Get all patient ids\n",
    "pattern, suffix = \"*_ccf_table_pyclone_clean.csv\", \"_ccf_table_pyclone_clean.csv\"\n",
    "file_paths = glob.glob(os.path.join(TRACERX_DATA_DIR, pattern))\n",
    "pids = [os.path.basename(file_path).replace(suffix, \"\") for file_path in file_paths]\n",
    "len(pids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c127adf7",
   "metadata": {},
   "source": [
    "### Extract TRACERx provided information on trees and phyloCCFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "292f719e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRUK0352\n"
     ]
    }
   ],
   "source": [
    "CORRECTED_TREE_STR = \"$graph_pyclone$Corrected_tree\"\n",
    "CCF_TABLE_STR = \"$nested_pyclone$ccf_cluster_table\"\n",
    "CLONALITY_TABLE_STR = \"$clonality_out$clonality_table_corrected\"\n",
    "PYCLONE_CLSTR_STR = \"PycloneCluster\"\n",
    "GEN_DIST_STR = \"$graph_pyclone$edgelength\"\n",
    "MAX_REACHED_STR = \"[ reached 'max' \"\n",
    "SKIP_STRINGS = [\"i\", \"last_ancestor terminal_node\"]\n",
    "\n",
    "import json \n",
    "from pyensembl import EnsemblRelease\n",
    "ensembl = EnsemblRelease(75) # hg19\n",
    "\n",
    "def collect_data(fn, matching_str):\n",
    "    with open(fn, \"r\") as f:\n",
    "        data = []\n",
    "        collect = False\n",
    "\n",
    "        for line in f:\n",
    "            if matching_str in line:\n",
    "                collect = True\n",
    "            elif collect:\n",
    "                line = line.strip()\n",
    "                if not line or MAX_REACHED_STR in line:  # Empty line or newline character encountered\n",
    "                    collect = False\n",
    "                else:\n",
    "                    items = line.split()\n",
    "                    data.append(items)\n",
    "        return data\n",
    "    \n",
    "def get_gene_name(chromosome, position):\n",
    "    # Fetch the gene that overlaps with the specified position\n",
    "    gene = ensembl.genes_at_locus(chromosome, position)\n",
    "    if gene:\n",
    "        return gene[0].gene_name\n",
    "    else:\n",
    "        return f\"{chromosome}:{position}\"\n",
    "    \n",
    "def write_best_tree(pid):\n",
    "    with open(os.path.join(TRACERX_DATA_DIR, f\"{pid}.txt\"), \"r\") as f:\n",
    "        edges = []\n",
    "        unique_clusters = set()\n",
    "        collect = False\n",
    "        for line in f:\n",
    "            if CORRECTED_TREE_STR in line:\n",
    "                collect = True\n",
    "            elif collect:\n",
    "                line = line.strip()\n",
    "                if line:  # If the line is not empty\n",
    "                    if line not in SKIP_STRINGS:\n",
    "                        items = line.replace('\\\"', \"\").split()\n",
    "                        edges.append((int(items[1]), int(items[2]))) \n",
    "                        unique_clusters.add(int(items[1]))\n",
    "                        unique_clusters.add(int(items[2]))\n",
    "                else:  # Empty line or newline character encountered\n",
    "                    collect = False\n",
    "    unique_clusters = sorted(list(unique_clusters)) \n",
    "    # Make it zero-indexed, and remove any clusters not used in trees\n",
    "    old_clust_to_new_clust = {unique_clusters[i]:i for i in range(len(unique_clusters))}\n",
    "    with open(os.path.join(OUTPUT_DIR, f\"{pid}_tree.txt\"), 'w') as f:\n",
    "        for edge in edges:\n",
    "            i = old_clust_to_new_clust[edge[0]]\n",
    "            j = old_clust_to_new_clust[edge[1]]\n",
    "            f.write(f\"{i} {j}\")\n",
    "            f.write(\"\\n\")\n",
    "    return old_clust_to_new_clust\n",
    "\n",
    "def write_gen_dist(pid, old_clust_to_new_clust):\n",
    "    fn = os.path.join(TRACERX_DATA_DIR, f\"{pid}.txt\")\n",
    "    with open(fn, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "        # Initialize variables\n",
    "        edge_lengths_started = False\n",
    "        edge_lengths_dict = {}\n",
    "        keys, values = [], []\n",
    "        for line in lines:\n",
    "            # Check for the starting line of edge lengths\n",
    "            if \"$graph_pyclone$edgelength\" in line:\n",
    "                edge_lengths_started = True\n",
    "                ctr = 0\n",
    "                continue\n",
    "            # Stop collecting edge lengths if the trunk section starts\n",
    "            if \"$graph_pyclone$trunk\" in line:\n",
    "                break\n",
    "            # Collect edge lengths\n",
    "            if edge_lengths_started:\n",
    "                ctr += 1\n",
    "                # Split line by spaces and filter out empty strings\n",
    "                parts = list(filter(None, line.strip().split(\" \")))\n",
    "                # If parts contain integers, they are the keys\n",
    "                if ctr % 2 == 0:\n",
    "                    keys.extend([int(part) for part in parts])\n",
    "                # If parts contain integers, they are the values\n",
    "                else:\n",
    "                    values.extend([int(part) for part in parts])\n",
    "                    # Build dictionary from keys and values\n",
    "    edge_lengths_dict = {old_clust_to_new_clust[k]:v for k,v in zip(keys,values) if k in old_clust_to_new_clust}\n",
    "    with open(os.path.join(OUTPUT_DIR, f'{pid}_edge_lengths.json'), 'w') as f:\n",
    "        json.dump(edge_lengths_dict, f, indent=4)\n",
    "    \n",
    "def write_cluster_to_mutation_names(pid, old_clust_to_new_clust):\n",
    "    fn = os.path.join(TRACERX_DATA_DIR, f\"{pid}.txt\")\n",
    "    data = collect_data(fn, PYCLONE_CLSTR_STR)\n",
    "    clstr_to_mut_names = dict()\n",
    "    for entry in data:\n",
    "        # Only keep data for clusters actually used in trees\n",
    "        if int(entry[1]) not in old_clust_to_new_clust:\n",
    "            continue\n",
    "        clstr = old_clust_to_new_clust[int(entry[1])]\n",
    "        mut_items = entry[0].split(\":\")\n",
    "        gene_name = get_gene_name(mut_items[1], int(mut_items[2]))\n",
    "        if clstr not in clstr_to_mut_names:\n",
    "            clstr_to_mut_names[clstr] = []\n",
    "        clstr_to_mut_names[clstr].append(gene_name)\n",
    "    assert(len(clstr_to_mut_names.keys())==len(old_clust_to_new_clust.values()))\n",
    "    with open(os.path.join(OUTPUT_DIR, f'{pid}_cluster_id_to_mut_names.json'), 'w') as f:\n",
    "        json.dump(clstr_to_mut_names, f, indent=4)\n",
    "    \n",
    "def format_df_data(data, old_clust_to_new_clust):\n",
    "    sample_names,df_data = [],{}\n",
    "    for d in data:\n",
    "        if \"CRUK\" in d[0]:\n",
    "            sample_names.extend(d)\n",
    "        else:\n",
    "            # Only keep data for clusters actually used in trees\n",
    "            if int(d[0]) in old_clust_to_new_clust:\n",
    "                cluster_num = old_clust_to_new_clust[int(d[0])]\n",
    "                if cluster_num not in df_data:\n",
    "                    df_data[cluster_num] = []\n",
    "                df_data[cluster_num].extend(d[1:])\n",
    "    df = pd.DataFrame.from_dict(df_data, columns=sample_names, orient='index')\n",
    "    df = df.rename_axis('cluster').reset_index()\n",
    "    return df\n",
    "    \n",
    "def write_clonalities(pid, old_clust_to_new_clust):\n",
    "    fn = os.path.join(TRACERX_DATA_DIR, f\"{pid}.txt\")\n",
    "    data = collect_data(fn, CLONALITY_TABLE_STR)\n",
    "    df = format_df_data(data, old_clust_to_new_clust)\n",
    "    df.to_csv(os.path.join(OUTPUT_DIR, f\"{pid}_clonalities.csv\"), index=False)\n",
    "    \n",
    "def write_clone_phylo_ccfs(pid, old_clust_to_new_clust):\n",
    "    fn = os.path.join(TRACERX_DATA_DIR, f\"{pid}.txt\")\n",
    "    data = collect_data(fn, CCF_TABLE_STR)\n",
    "    df = format_df_data(data, old_clust_to_new_clust)\n",
    "    df.to_csv(os.path.join(OUTPUT_DIR, f\"{pid}_phyloccfs.csv\"), index=False)\n",
    "\n",
    "for pid in pids:\n",
    "    print(pid)\n",
    "    old_clust_to_new_clust = write_best_tree(pid)\n",
    "    write_clone_phylo_ccfs(pid, old_clust_to_new_clust)\n",
    "    write_clonalities(pid, old_clust_to_new_clust)\n",
    "    write_cluster_to_mutation_names(pid, old_clust_to_new_clust)\n",
    "    write_gen_dist(pid, old_clust_to_new_clust)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d18271c",
   "metadata": {},
   "source": [
    "### Get clone presences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6004df25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from metient.util import vertex_labeling_util as vutil\n",
    "\n",
    "    \n",
    "def get_node_to_sample_to_ccf(pid):\n",
    "    # Convert phyloCCF info to dict\n",
    "    ccf_fn = os.path.join(OUTPUT_DIR, f\"{pid}_phyloccfs.csv\")\n",
    "    ccf_df = pd.read_csv(ccf_fn, index_col=False)\n",
    "    ccf_df.set_index('cluster', inplace=True)\n",
    "    node_to_sample_to_phyloccf = ccf_df.to_dict(orient='index')\n",
    "    \n",
    "    # Convert clonality info to dict\n",
    "    clonality_fn = os.path.join(OUTPUT_DIR, f\"{pid}_clonalities.csv\")\n",
    "    clonality_df = pd.read_csv(clonality_fn, index_col=False)\n",
    "    clonality_df.set_index('cluster', inplace=True)\n",
    "    node_to_sample_to_clonality = clonality_df.to_dict(orient='index')\n",
    "\n",
    "    for node in node_to_sample_to_clonality:\n",
    "        for sample in node_to_sample_to_clonality[node]:\n",
    "            node_to_sample_to_phyloccf[node][sample] /= 100.0\n",
    "            if node_to_sample_to_clonality[node][sample] == 'clonal':\n",
    "                node_to_sample_to_phyloccf[node][sample] = 1.0\n",
    "\n",
    "    return node_to_sample_to_phyloccf\n",
    "\n",
    "def get_node_to_sample_to_clone_proportion(tree, samples, node_to_sample_to_phyloccf):\n",
    "    node_to_sample_to_clone_proportion = {}\n",
    "    leaves = vutil.get_leaves(tree)\n",
    "    print(\"leaves\", leaves)\n",
    "    for leaf in leaves:\n",
    "        node_to_sample_to_clone_proportion[leaf] = {}\n",
    "        for sample in samples:\n",
    "            node_to_sample_to_clone_proportion[leaf][sample] = node_to_sample_to_phyloccf[leaf][sample]\n",
    "    \n",
    "    \n",
    "    reverse_bfs = vutil.reverse_bfs_order(tree)\n",
    "    print(\"reverse_bfs\", reverse_bfs) \n",
    "    for sample in samples:\n",
    "        for node in reverse_bfs:\n",
    "            if node not in node_to_sample_to_clone_proportion:\n",
    "                node_to_sample_to_clone_proportion[node] = {}\n",
    "\n",
    "            descendants = vutil.get_descendants(tree, node)\n",
    "            descendant_ccf_sum = sum([node_to_sample_to_phyloccf[d][sample] for d in descendants])\n",
    "            node_to_sample_to_clone_proportion[node][sample] = node_to_sample_to_phyloccf[node][sample]-descendant_ccf_sum\n",
    "    \n",
    "    \n",
    "    return node_to_sample_to_clone_proportion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951ace56",
   "metadata": {},
   "source": [
    "### Get sample information and mutation information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "400a008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from metient.util import plotting_util as plutil\n",
    "\n",
    "sample_info_df = pd.read_csv(os.path.join(REPO_DIR, \"data/tracerx_nsclc/\",\"sample_overview_original.txt\"), sep=\"\\t\")\n",
    "\n",
    "def remove_region_suffix(input_string):\n",
    "    pattern = r'\\.R\\d+$'\n",
    "    modified_string = re.sub(pattern, '', input_string)\n",
    "    return modified_string\n",
    "\n",
    "def get_site_to_samples(pid):\n",
    "    site_to_samples = {}\n",
    "    site_to_category = {} # primary or metstasis\n",
    "    patient_samples = sample_info_df[sample_info_df['patient_id']==pid]\n",
    "    for _,row in patient_samples.iterrows():\n",
    "        region = row['region']\n",
    "        sample_type = row['sampleTypeDetail']\n",
    "        site = remove_region_suffix(region).replace(pid, sample_type)\n",
    "        if site not in site_to_samples:\n",
    "            site_to_samples[site] = []\n",
    "        site_to_samples[site].append(region)\n",
    "        site_to_category[site] = row['sampleType']\n",
    "    return site_to_samples, site_to_category\n",
    "\n",
    "def get_clstr_to_muts(pid):\n",
    "    with open(os.path.join(OUTPUT_DIR, f'{pid}_cluster_id_to_mut_names.json'), 'r') as f:\n",
    "        mut_names_data = json.load(f)\n",
    "    with open(os.path.join(OUTPUT_DIR, f'{pid}_edge_lengths.json'), 'r') as f:\n",
    "        edge_data = json.load(f)\n",
    "        \n",
    "    clstr_to_muts_info = {}\n",
    "    for clstr in mut_names_data:\n",
    "        mutations = mut_names_data[clstr]\n",
    "        shortened_label = plutil.get_pruned_mut_label(mutations, True, True)\n",
    "        clstr_to_muts_info[int(clstr)] = (mutations, shortened_label, edge_data[clstr])\n",
    "    return clstr_to_muts_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aa0a52",
   "metadata": {},
   "source": [
    "### Write all inputs for Metient to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0122d225",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRUK0352\n",
      "leaves [9, 10, 14, 15, 16, 21, 22, 23]\n",
      "reverse_bfs [23, 26, 18, 15, 16, 22, 21, 8, 25, 27, 12, 28, 7, 20, 29, 19, 14, 10, 9, 24, 11, 17, 13, 5, 3, 2, 6, 4, 1, 0]\n",
      "    anatomical_site_index anatomical_site_label  cluster_index  \\\n",
      "0                       0         primary_SU_T1              0   \n",
      "1                       1            LN_SU_FLN1              0   \n",
      "2                       0         primary_SU_T1              1   \n",
      "3                       1            LN_SU_FLN1              1   \n",
      "4                       0         primary_SU_T1              2   \n",
      "5                       1            LN_SU_FLN1              2   \n",
      "6                       0         primary_SU_T1              3   \n",
      "7                       1            LN_SU_FLN1              3   \n",
      "8                       0         primary_SU_T1              4   \n",
      "9                       1            LN_SU_FLN1              4   \n",
      "10                      0         primary_SU_T1              5   \n",
      "11                      1            LN_SU_FLN1              5   \n",
      "12                      0         primary_SU_T1              6   \n",
      "13                      1            LN_SU_FLN1              6   \n",
      "14                      0         primary_SU_T1              7   \n",
      "15                      1            LN_SU_FLN1              7   \n",
      "16                      0         primary_SU_T1              8   \n",
      "17                      1            LN_SU_FLN1              8   \n",
      "18                      0         primary_SU_T1              9   \n",
      "19                      1            LN_SU_FLN1              9   \n",
      "20                      0         primary_SU_T1             10   \n",
      "21                      1            LN_SU_FLN1             10   \n",
      "22                      0         primary_SU_T1             11   \n",
      "23                      1            LN_SU_FLN1             11   \n",
      "24                      0         primary_SU_T1             12   \n",
      "25                      1            LN_SU_FLN1             12   \n",
      "26                      0         primary_SU_T1             13   \n",
      "27                      1            LN_SU_FLN1             13   \n",
      "28                      0         primary_SU_T1             14   \n",
      "29                      1            LN_SU_FLN1             14   \n",
      "30                      0         primary_SU_T1             15   \n",
      "31                      1            LN_SU_FLN1             15   \n",
      "32                      0         primary_SU_T1             16   \n",
      "33                      1            LN_SU_FLN1             16   \n",
      "34                      0         primary_SU_T1             17   \n",
      "35                      1            LN_SU_FLN1             17   \n",
      "36                      0         primary_SU_T1             18   \n",
      "37                      1            LN_SU_FLN1             18   \n",
      "38                      0         primary_SU_T1             19   \n",
      "39                      1            LN_SU_FLN1             19   \n",
      "40                      0         primary_SU_T1             20   \n",
      "41                      1            LN_SU_FLN1             20   \n",
      "42                      0         primary_SU_T1             21   \n",
      "43                      1            LN_SU_FLN1             21   \n",
      "44                      0         primary_SU_T1             22   \n",
      "45                      1            LN_SU_FLN1             22   \n",
      "46                      0         primary_SU_T1             23   \n",
      "47                      1            LN_SU_FLN1             23   \n",
      "48                      0         primary_SU_T1             24   \n",
      "49                      1            LN_SU_FLN1             24   \n",
      "50                      0         primary_SU_T1             25   \n",
      "51                      1            LN_SU_FLN1             25   \n",
      "52                      0         primary_SU_T1             26   \n",
      "53                      1            LN_SU_FLN1             26   \n",
      "54                      0         primary_SU_T1             27   \n",
      "55                      1            LN_SU_FLN1             27   \n",
      "56                      0         primary_SU_T1             28   \n",
      "57                      1            LN_SU_FLN1             28   \n",
      "58                      0         primary_SU_T1             29   \n",
      "59                      1            LN_SU_FLN1             29   \n",
      "\n",
      "         cluster_label  present site_category  num_mutations  \n",
      "0          PDGFRA;EGFR        0       primary            619  \n",
      "1          PDGFRA;EGFR        0    metastasis            619  \n",
      "2            HGF;EPHA3        0       primary            468  \n",
      "3            HGF;EPHA3        0    metastasis            468  \n",
      "4           PAX5;PTPRD        1       primary            187  \n",
      "5           PAX5;PTPRD        0    metastasis            187  \n",
      "6         NFE2L2;KMT2C        0       primary            103  \n",
      "7         NFE2L2;KMT2C        0    metastasis            103  \n",
      "8                 FAT1        1       primary             74  \n",
      "9                 FAT1        0    metastasis             74  \n",
      "10          MSH3;SPTA1        0       primary             67  \n",
      "11          MSH3;SPTA1        0    metastasis             67  \n",
      "12              PDGFRA        0       primary             61  \n",
      "13              PDGFRA        0    metastasis             61  \n",
      "14       AADACL4;AHDC1        1       primary             48  \n",
      "15       AADACL4;AHDC1        0    metastasis             48  \n",
      "16        FAM213B;SELP        1       primary             42  \n",
      "17        FAM213B;SELP        0    metastasis             42  \n",
      "18        DLGAP3;SYCP1        1       primary             30  \n",
      "19        DLGAP3;SYCP1        0    metastasis             30  \n",
      "20     KIAA0319L;QSOX1        1       primary             27  \n",
      "21     KIAA0319L;QSOX1        0    metastasis             27  \n",
      "22               SPTA1        0       primary             17  \n",
      "23               SPTA1        0    metastasis             17  \n",
      "24     ADAMTSL4;PRRC2C        1       primary             16  \n",
      "25     ADAMTSL4;PRRC2C        0    metastasis             16  \n",
      "26         DARC;PPFIA4        1       primary             13  \n",
      "27         DARC;PPFIA4        0    metastasis             13  \n",
      "28           NBAS;DYSF        1       primary             13  \n",
      "29           NBAS;DYSF        0    metastasis             13  \n",
      "30        CSRNP3;OR5K1        1       primary             13  \n",
      "31        CSRNP3;OR5K1        0    metastasis             13  \n",
      "32               SPTA1        0       primary             10  \n",
      "33               SPTA1        1    metastasis             10  \n",
      "34       OR2B11;IQSEC1        1       primary             10  \n",
      "35       OR2B11;IQSEC1        0    metastasis             10  \n",
      "36          CHD5;FSIP2        1       primary              9  \n",
      "37          CHD5;FSIP2        0    metastasis              9  \n",
      "38       OR10T2;HNRNPU        0       primary              9  \n",
      "39       OR10T2;HNRNPU        0    metastasis              9  \n",
      "40      OR6K6;RABGAP1L        0       primary              9  \n",
      "41      OR6K6;RABGAP1L        0    metastasis              9  \n",
      "42          MUL1;INSRR        1       primary              8  \n",
      "43          MUL1;INSRR        0    metastasis              8  \n",
      "44    C1orf112;LAPTM4A        1       primary              8  \n",
      "45    C1orf112;LAPTM4A        0    metastasis              8  \n",
      "46              MAP3K4        1       primary              6  \n",
      "47              MAP3K4        0    metastasis              6  \n",
      "48         CPLX1;ACOX3        1       primary              6  \n",
      "49         CPLX1;ACOX3        0    metastasis              6  \n",
      "50         CTNNA2;NKD2        1       primary              6  \n",
      "51         CTNNA2;NKD2        0    metastasis              6  \n",
      "52         AMER3;MORC1        1       primary              5  \n",
      "53         AMER3;MORC1        0    metastasis              5  \n",
      "54          FGGY;LAMB1        0       primary              5  \n",
      "55          FGGY;LAMB1        1    metastasis              5  \n",
      "56  DNM3;RP5-1132H15.1        1       primary              5  \n",
      "57  DNM3;RP5-1132H15.1        0    metastasis              5  \n",
      "58        BCL9;ABHD14B        0       primary              5  \n",
      "59        BCL9;ABHD14B        0    metastasis              5  \n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from metient.util import data_extraction_util as dutil\n",
    "\n",
    "def process_patient(pid):\n",
    "    print(pid)\n",
    "    \n",
    "    tree_fn = os.path.join(OUTPUT_DIR, f\"{pid}_tree.txt\")\n",
    "    tree = dutil.get_adjacency_matrix_from_txt_edge_list(tree_fn)\n",
    "    num_nodes = tree.shape[0]\n",
    "    \n",
    "    node_to_sample_to_phyloccf = get_node_to_sample_to_ccf(pid)\n",
    "\n",
    "    samples = set(node_to_sample_to_phyloccf[0].keys())\n",
    "    node_to_sample_to_clone_proportion = get_node_to_sample_to_clone_proportion(tree, samples, node_to_sample_to_phyloccf)\n",
    "\n",
    "    site_to_samples, site_to_category = get_site_to_samples(pid)\n",
    "    clstr_to_muts_info = get_clstr_to_muts(pid)\n",
    "    data = []\n",
    "    for node in range(num_nodes):\n",
    "        for site_idx, site_label in enumerate(site_to_samples.keys()):\n",
    "            associated_samples = site_to_samples[site_label]\n",
    "            presence = 0\n",
    "            for sample in associated_samples:\n",
    "                if node_to_sample_to_clone_proportion[node][sample] > 0.0:\n",
    "                    presence = 1\n",
    "            site_category = site_to_category[site_label]\n",
    "            mutations = clstr_to_muts_info[node][0]\n",
    "            character_label = clstr_to_muts_info[node][1]\n",
    "            num_mutations = clstr_to_muts_info[node][2]\n",
    "            \n",
    "            data.append([site_idx, site_label, node, character_label, presence, site_category, num_mutations])\n",
    "   \n",
    "    new_snvs_df = pd.DataFrame(data, columns=['anatomical_site_index', 'anatomical_site_label', 'cluster_index',\n",
    "                                              'cluster_label', 'present', 'site_category', 'num_mutations'])\n",
    "    print(new_snvs_df)\n",
    "    output_fn = os.path.join(OUTPUT_DIR, f\"{pid}_SNVs.tsv\")\n",
    "    with open(output_fn, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file, delimiter='\\t')\n",
    "        writer.writerow(new_snvs_df.columns)\n",
    "        for _, row in new_snvs_df.iterrows():\n",
    "            writer.writerow(row)\n",
    "\n",
    "for pid in pids:\n",
    "    process_patient(pid)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:met]",
   "language": "python",
   "name": "conda-env-met-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
